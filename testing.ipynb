{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# import necessary packages\n",
    "import os\n",
    "import time\n",
    "import tweepy\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib\n",
    "matplotlib.use('Agg')\n",
    "import matplotlib.pyplot as plt\n",
    "from datetime import datetime\n",
    "import seaborn as sns\n",
    "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
    "analyzer = SentimentIntensityAnalyzer()\n",
    "\n",
    "api_key = os.getenv('api_key')\n",
    "api_sec = os.getenv('api_sec')\n",
    "token = os.getenv('token')\n",
    "token_sec = os.getenv('token_sec')\n",
    "\n",
    "# Setup Tweepy API Authentication\n",
    "auth = tweepy.OAuthHandler(api_key, api_sec)\n",
    "auth.set_access_token(token, token_sec)\n",
    "api = tweepy.API(auth, parser=tweepy.parsers.JSONParser())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def new_ids(last_id):\n",
    "    #looks for new mentions & creates a list of the accounts to analyze & those to attribute\n",
    "\n",
    "    # Search for all tweets\n",
    "    public_tweets = api.search(\"@plot_kb\", count=100, result_type=\"recent\", since_id=last_id)\n",
    "\n",
    "    # First, check if there are any new tweets\n",
    "    if public_tweets[\"statuses\"]:\n",
    "    \n",
    "        # create empty lists to store screen names\n",
    "        to_plot = []\n",
    "        to_attribute = []\n",
    "\n",
    "        # loop through the tweets & store the screen names of the account to be analyzed &\n",
    "        # the account that requested the analysis (only 1 analysis per mention)\n",
    "        for tweet in public_tweets['statuses']:\n",
    "            for mention in tweet['entities']['user_mentions']:\n",
    "                if mention['screen_name'] != 'plot_kb':\n",
    "                    plot_name = mention['screen_name']\n",
    "                    to_attribute.append(tweet['user']['screen_name'])\n",
    "                    to_plot.append(plot_name)\n",
    "                    break\n",
    "        if len(to_plot) > 0:\n",
    "            return({\"to_plot\": to_plot, \"to_attribute\": to_attribute})\n",
    "        else:\n",
    "            return([last_id])\n",
    "    else:\n",
    "        return([last_id])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tweets = api.user_timeline('plot_kb', count = 100)\n",
    "last_id = my_tweets[0]['id']\n",
    "public_tweets = api.search(\"@plot_kb\", count=100, result_type=\"recent\", since_id=last_id)\n",
    "\n",
    "    # First, check if there are any new tweets\n",
    "if public_tweets[\"statuses\"]:\n",
    "    \n",
    "        # create empty lists to store screen names\n",
    "    to_plot = []\n",
    "    to_attribute = []\n",
    "\n",
    "        # loop through the tweets & store the screen names of the account to be analyzed &\n",
    "        # the account that requested the analysis (only 1 analysis per mention)\n",
    "    for tweet in public_tweets['statuses']:\n",
    "        for mention in tweet['entities']['user_mentions']:\n",
    "            if mention['screen_name'] != 'plot_kb':\n",
    "                plot_name = mention['screen_name']\n",
    "                to_attribute.append(tweet['user']['screen_name'])\n",
    "                to_plot.append(plot_name)\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Oprah']"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['kk_blev']"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "to_attribute"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def tweet_sentiment(target_user, attribution):\n",
    "    # plot the sentiment analysis of the target user's last 500 tweets\n",
    "    \n",
    "    try:\n",
    "        compound_list = []\n",
    "        \n",
    "        #Loop through 25 pages of tweets (total 500 tweets)\n",
    "        for x in range(25):\n",
    "\n",
    "            # Get all tweets from home feed\n",
    "            public_tweets = api.user_timeline(target_user, page=x)  \n",
    "            \n",
    "            # Loop through all tweets\n",
    "            for tweet in public_tweets:\n",
    "\n",
    "                # Run Vader Analysis on each tweet\n",
    "                results = analyzer.polarity_scores(tweet[\"text\"])\n",
    "\n",
    "                # Add each compound score to the compound_list\n",
    "                compound_list.append(results[\"compound\"])\n",
    "\n",
    "        # create an array of the tweet index from 0 to -499\n",
    "        tweet_no = sorted(np.arange(-len(compound_list), 0), reverse = True)\n",
    "    \n",
    "        # average the compound score\n",
    "        avg_score = round(np.mean(compound_list),2)\n",
    "        \n",
    "        # create a plot of the compound score for each tweet\n",
    "        sns.set_style(\"darkgrid\")\n",
    "        plt.plot(tweet_no, compound_list, color = 'k', marker = '.', lw=.5)\n",
    "        plt.plot([-len(compound_list), 0], [avg_score, avg_score], color = 'm', linewidth=2)\n",
    "        lgd = plt.legend(labels = ['tweet score', f'avg score ({avg_score})'], title = 'Legend', bbox_to_anchor=(1,1))\n",
    "        current_date = datetime.strftime(datetime.now(), '%m/%d/%y')\n",
    "        plt.ylim(-1, 1)\n",
    "        plt.xlabel(\"Tweets Ago\")\n",
    "        plt.ylabel(\"Tweet Polarity\")\n",
    "        plt.title(f\"Sentiment Analysis of @{target_user} Tweets ({current_date})\")\n",
    "\n",
    "        # save the plot to a file\n",
    "        filename = temp.png\n",
    "        plt.savefig(filename, bbox_extra_artists=(lgd,), bbox_inches='tight', dpi = 300)\n",
    "        plt.close()\n",
    "        \n",
    "        # reset compound list & avg_score\n",
    "        compound_list = []\n",
    "        avg_score = \"\"\n",
    "        \n",
    "        # tweet out the plot\n",
    "        api.update_with_media(filename,\n",
    "                              f\"Tweet sentiment analysis for @{target_user} as requested by @{attribution}\")\n",
    "    except:\n",
    "        api.update_status(f\"@{attribution} sorry, there was an error with the analysis of @{target_user}. I'll look into it and try to let you know why.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "target_user = to_plot[0]\n",
    "\n",
    "compound_list = []\n",
    "        \n",
    "        #Loop through 25 pages of tweets (total 500 tweets)\n",
    "for x in range(25):\n",
    "\n",
    "            # Get all tweets from home feed\n",
    "    public_tweets = api.user_timeline(target_user, page=x)  \n",
    "            \n",
    "            # Loop through all tweets\n",
    "    for tweet in public_tweets:\n",
    "\n",
    "                # Run Vader Analysis on each tweet\n",
    "        results = analyzer.polarity_scores(tweet[\"text\"])\n",
    "\n",
    "                # Add each compound score to the compound_list\n",
    "        compound_list.append(results[\"compound\"])\n",
    "\n",
    "        # create an array of the tweet index from 0 to -499\n",
    "tweet_no = sorted(np.arange(-len(compound_list), 0), reverse = True)\n",
    "    \n",
    "        # average the compound score\n",
    "avg_score = round(np.mean(compound_list),2)\n",
    "       "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'temp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-9-469ea1ca1d73>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m     12\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     13\u001b[0m        \u001b[1;31m# save the plot to a file\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 14\u001b[1;33m \u001b[0mfilename\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtemp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mpng\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     15\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msavefig\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfilename\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbbox_extra_artists\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mlgd\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mbbox_inches\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;34m'tight'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdpi\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m300\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     16\u001b[0m \u001b[0mplt\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mshow\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'temp' is not defined"
     ]
    }
   ],
   "source": [
    " \n",
    "        # create a plot of the compound score for each tweet\n",
    "sns.set_style(\"darkgrid\")\n",
    "plt.plot(tweet_no, compound_list, color = 'k', marker = '.', lw=.5)\n",
    "plt.plot([-len(compound_list), 0], [avg_score, avg_score], color = 'm', linewidth=2)\n",
    "lgd = plt.legend(labels = ['tweet score', f'avg score ({avg_score})'], title = 'Legend', bbox_to_anchor=(1,1))\n",
    "current_date = datetime.strftime(datetime.now(), '%m/%d/%y')\n",
    "plt.ylim(-1, 1)\n",
    "plt.xlabel(\"Tweets Ago\")\n",
    "plt.ylabel(\"Tweet Polarity\")\n",
    "plt.title(f\"Sentiment Analysis of @{target_user} Tweets ({current_date})\")\n",
    "\n",
    "        # save the plot to a file\n",
    "filename = temp.png\n",
    "plt.savefig(filename, bbox_extra_artists=(lgd,), bbox_inches='tight', dpi = 300)\n",
    "plt.show()\n",
    "plt.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# every 5 minutes, scan for new mentions & update with plots\n",
    "while True:\n",
    "    \n",
    "    print(f\"starting analysis at {datetime.strftime(datetime.now(),'%d-%m-%Y %H:%M:%S')}\")\n",
    "    \n",
    "    # get id for last tweet issued from account\n",
    "    my_tweets = api.user_timeline('plot_kb', count = 100)\n",
    "    last_id = my_tweets[0]['id']\n",
    "\n",
    "    # run new_ids to see if there are new plot requests since the last tweet\n",
    "    new = new_ids(last_id)\n",
    "    \n",
    "    # if there are new tweets, new will be a dictionary, so....\n",
    "    if type(new) == dict:\n",
    "        \n",
    "        # make a dataframe out of it\n",
    "        df = pd.DataFrame(new)\n",
    "            \n",
    "        # create an empty list to populate with the recently analyzed accounts\n",
    "        # so we don't re-analyze them too often    \n",
    "        recently_analyzed = []\n",
    "\n",
    "        print('analyzing previous tweets')\n",
    "        for tweet in my_tweets:\n",
    "            try:\n",
    "                # grab the screen name for accounts that have been analyzed recently\n",
    "                user = tweet['entities']['user_mentions'][0]['screen_name']\n",
    "                # add them to the recently_analyzed list\n",
    "                recently_analyzed.append(user)\n",
    "            except IndexError:\n",
    "                print('1 tweet has no mentions')\n",
    "        print('finished analyzing previous tweets')\n",
    "        \n",
    "        # for each of the mentions in the new mentions...\n",
    "        for index, row in df.iterrows():\n",
    "            # if the account hasn't been analyzed recently\n",
    "            if row['to_plot'] not in recently_analyzed:\n",
    "                print(f\"analyzing {row['to_plot']}\")\n",
    "                # run the tweet_sentiment function on the account requested\n",
    "                tweet_sentiment(row['to_plot'], row['to_attribute'])\n",
    "                # add that account to the recently_analyzed list\n",
    "                recently_analyzed.append(row['to_plot'])\n",
    "                print(f\"finished analyzing {row['to_plot']}\")\n",
    "            else:\n",
    "                print(f\"{row['to_plot']} was already analyzed recently, skipping\")\n",
    "        \n",
    "        print('Done analyzing new tweets. Going to sleep for 5 minutes. Zzzzz....\\n')\n",
    "        time.sleep(300)\n",
    "    else:\n",
    "        print('No new tweets to analyze. Going to sleep for 5 minutes. Zzzzz....\\n')\n",
    "        time.sleep(300)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
